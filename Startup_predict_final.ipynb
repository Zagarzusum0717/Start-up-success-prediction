{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc1c90e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# 1. üì¶ SMOTE Logistic Regression .pkl —Ñ–∞–π–ª—É—É–¥—ã–≥ –∞—á–∞–∞–ª–∞—Ö\n",
    "model = joblib.load(\"startup_model_logreg_smote.pkl\")\n",
    "scaler = joblib.load(\"scaler_logreg_smote.pkl\")\n",
    "label_encoders = joblib.load(\"label_encoders_logreg_smote.pkl\")\n",
    "feature_order = joblib.load(\"feature_order_logreg_smote.pkl\")\n",
    "\n",
    "# 2. üß† –¢–∞–∞–º–∞–≥ –≥–∞—Ä–≥–∞—Ö —Ñ—É–Ω–∫—Ü\n",
    "def predict(state, category, funding, relationships, milestones, participants, vc, angel, top500):\n",
    "    features = {col: 0 for col in feature_order}\n",
    "\n",
    "    # –ú—É–∂\n",
    "    if state in label_encoders['state_code'].classes_:\n",
    "        features['state_code'] = label_encoders['state_code'].transform([state])[0]\n",
    "    features[f\"is_{state}\" if f\"is_{state}\" in feature_order else \"is_otherstate\"] = 1\n",
    "\n",
    "    # –°–∞–ª–±–∞—Ä\n",
    "    if category in label_encoders['category_code'].classes_:\n",
    "        features['category_code'] = label_encoders['category_code'].transform([category])[0]\n",
    "    features[f\"is_{category}\" if f\"is_{category}\" in feature_order else \"is_othercategory\"] = 1\n",
    "\n",
    "    # –¢–æ–æ–Ω –±–æ–ª–æ–Ω –ª–æ–≥–∏–∫ —Ç–∞–ª–±–∞—Ä—É—É–¥\n",
    "    features['funding_total_usd'] = funding * 1_000_000\n",
    "    features['relationships'] = relationships\n",
    "    features['milestones'] = milestones\n",
    "    features['avg_participants'] = participants\n",
    "    features['has_VC'] = int(vc)\n",
    "    features['has_angel'] = int(angel)\n",
    "    features['is_top500'] = int(top500)\n",
    "\n",
    "    # Default-required\n",
    "    features['closed_at'] = 0\n",
    "    features['status'] = 0\n",
    "\n",
    "    df = pd.DataFrame([features])[feature_order]\n",
    "    df_scaled = scaler.transform(df)\n",
    "    prob = model.predict_proba(df_scaled)[0]\n",
    "    pred = model.predict(df_scaled)[0]\n",
    "\n",
    "    # ‚úÖ –ó”©–≤–ª”©–º–∂—Ç—ç–π —Ö–∞—Ä–∏—É –±—É—Ü–∞–∞—Ö\n",
    "    if pred == 1:\n",
    "        msg = f\"‚úÖ –¢–∞–Ω–∞–π —Å—Ç–∞—Ä—Ç–∞–ø –∞–º–∂–∏–ª—Ç—Ç–∞–π –±–æ–ª–æ—Ö –º–∞–≥–∞–¥–ª–∞–ª: {prob[1]:.2%}.\\n\\nüöÄ –ó”©–≤–ª”©–º–∂: –ò–ª“Ø“Ø milestone —Ö—ç—Ä—ç–≥–∂“Ø“Ø–ª–∂, —Ö”©—Ä”©–Ω–≥”© –æ—Ä—É—É–ª–∞–ª—Ç–∞–∞ —Ç–æ–≥—Ç–≤–æ—Ä—Ç–æ–π –Ω—ç–º—ç–≥–¥“Ø“Ø–ª—ç—ç—Ä—ç–π.\"\n",
    "    else:\n",
    "        msg = f\"‚ùå –¢–∞–Ω–∞–π —Å—Ç–∞—Ä—Ç–∞–ø –∞–º–∂–∏–ª—Ç–≥“Ø–π –±–æ–ª–æ—Ö –º–∞–≥–∞–¥–ª–∞–ª: {prob[0]:.2%}.\\n\\nüìâ –ó”©–≤–ª”©–º–∂: VC —ç—Å–≤—ç–ª angel —Ö”©—Ä”©–Ω–≥”© –æ—Ä—É—É–ª–∞–≥—á —Ç–∞—Ç–∞—Ö, –±–∞–≥–∏–π–Ω –±“Ø—Ç—Ü–∏–π–≥ –±—ç—Ö–∂“Ø“Ø–ª—ç—Ö —à–∞–∞—Ä–¥–ª–∞–≥–∞—Ç–∞–π –±–∞–π–∂ –º–∞–≥–∞–¥–≥“Ø–π.\"\n",
    "\n",
    "    return msg\n",
    "\n",
    "# 3. üåê Gradio chatbot-style interface\n",
    "with gr.Blocks(title=\"Startup Chatbot (LogReg + SMOTE)\") as chatbot:\n",
    "    gr.Markdown(\"## ü§ñ –°—Ç–∞—Ä—Ç–∞–ø –ê–º–∂–∏–ª—Ç—ã–Ω –¢–∞–∞–º–∞–≥–ª–∞–≥—á –ß–∞—Ç–±–æ—Ç (Logistic Regression + SMOTE)\")\n",
    "    gr.Markdown(\"–¢–∞ –∞—Å—É—É–ª—Ç–∞–¥ —Ö–∞—Ä–∏—É–ª–∞–∞–¥ ML –∑–∞–≥–≤–∞—Ä—ã–Ω —Ç–∞–∞–º–∞–≥ + –∑”©–≤–ª”©–º–∂”©”© –∞–≤–∞–∞—Ä–∞–π.\")\n",
    "\n",
    "    with gr.Row():\n",
    "        state = gr.Dropdown([\"CA\", \"NY\", \"TX\", \"MA\", \"otherstate\"], label=\"1. –ê–ª—å –º—É–∂–∏–¥ –±–∞–π—Ä–ª–∞–¥–∞–≥ –≤—ç?\")\n",
    "        category = gr.Dropdown([\"biotech\", \"software\", \"web\", \"othercategory\"], label=\"2. –Ø–º–∞—Ä —Å–∞–ª–±–∞—Ä—Ç –∞–∂–∏–ª–ª–∞–¥–∞–≥ –≤—ç?\")\n",
    "\n",
    "    funding = gr.Slider(0, 100, step=1, label=\"3. –•”©—Ä”©–Ω–≥”© (—Å–∞—è USD)\", value=1)\n",
    "    relationships = gr.Slider(0, 20, step=1, label=\"4. Co-founder –±–æ–ª–æ–Ω —Ö–∞—Ä–∏–ª—Ü–∞–∞–Ω—ã —Ç–æ–æ\", value=3)\n",
    "    milestones = gr.Slider(0, 10, step=1, label=\"5. Milestone-–∏–π–Ω —Ç–æ–æ\", value=2)\n",
    "    participants = gr.Slider(0, 10, step=1, label=\"6. –î—É–Ω–¥–∞–∂ —Ö”©—Ä”©–Ω–≥”© –æ—Ä—É—É–ª–∞–≥—á–∏–π–Ω —Ç–æ–æ\", value=4)\n",
    "\n",
    "    vc = gr.Checkbox(label=\"7. VC —Ö”©—Ä”©–Ω–≥”© –æ—Ä—É—É–ª–∞–≥—á—Ç–∞–π —é—É?\")\n",
    "    angel = gr.Checkbox(label=\"8. Angel —Ö”©—Ä”©–Ω–≥”© –æ—Ä—É—É–ª–∞–≥—á—Ç–∞–π —é—É?\")\n",
    "    top500 = gr.Checkbox(label=\"9. Top 500-–¥ –±–∞–≥—Ç—Å–∞–Ω —É—É?\")\n",
    "\n",
    "    btn = gr.Button(\"üìä –¢–∞–∞–º–∞–≥ –≥–∞—Ä–≥–∞—Ö\")\n",
    "    result = gr.Textbox(label=\"üß† –¢–∞–∞–º–∞–≥ –±–∞ –ó”©–≤–ª”©–º–∂\")\n",
    "\n",
    "    btn.click(fn=predict, inputs=[\n",
    "        state, category, funding, relationships,\n",
    "        milestones, participants, vc, angel, top500\n",
    "    ], outputs=result)\n",
    "\n",
    "chatbot.launch(share=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c54489fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Accuracy: 77.82%\n",
      "üìä F1-score: 77.25%\n",
      "‚úÖ –ë“Ø—Ö .pkl —Ñ–∞–π–ª—É—É–¥ SMOTE –∑–∞–≥–≤–∞—Ä–∞–∞—Ä “Ø“Ø—Å–≥—ç–≥–¥–ª—ç—ç.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "\n",
    "# 1. üì• CSV –¥–∞—Ç–∞–≥ —É–Ω—à–∏—Ö\n",
    "df = pd.read_csv(\"C:/Users/Dell/Downloads/Ecn325 data (1).csv\")  # ‚Üê –ó–∞–º—ã–≥ ”©”©—Ä–∏–π–Ω –∫–æ–º–ø—å—é—Ç–µ—Ä—Ç —Ç–∞–∞—Ä—É—É–ª–Ω–∞ —É—É\n",
    "\n",
    "# 2. üéØ Target —Ö”©—Ä–≤“Ø“Ø–ª—ç—Ö ('acquired'=1, 'closed'=0)\n",
    "df = df[df['status'].isin(['acquired', 'closed'])].copy()\n",
    "df['status'] = df['status'].map({'acquired': 1, 'closed': 0})\n",
    "\n",
    "# 3. üóëÔ∏è –•—ç—Ä—ç–≥–≥“Ø–π –±–∞–≥–∞–Ω—É—É–¥—ã–≥ —É—Å—Ç–≥–∞—Ö\n",
    "columns_to_drop = [\n",
    "    'Unnamed: 0', 'Unnamed: 6', 'id', 'name',\n",
    "    'object_id', 'state_code.1'\n",
    "]\n",
    "df.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# 4. üè∑Ô∏è –ö–∞—Ç–µ–≥–æ—Ä–∏ –±–∞–≥–∞–Ω—É—É–¥—ã–≥ Label Encode —Ö–∏–π—Ö\n",
    "label_encoders = {}\n",
    "categorical_cols = df.select_dtypes(include='object').columns\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].fillna(\"unknown\")\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# 5. üìä –¢–æ–æ–Ω —É—Ç–≥—É—É–¥—ã–Ω —Ö–æ–æ—Å–æ–Ω —É—Ç–≥—ã–≥ –¥—É–Ω–¥–∂–∞–∞—Ä –Ω”©—Ö”©—Ö\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].mean())\n",
    "\n",
    "# 6. üßÆ Features –±–∞ Target-–≥ —Å–∞–ª–≥–∞—Ö\n",
    "X = df.drop(columns=[\"status\"])\n",
    "y = df[\"status\"]\n",
    "\n",
    "# 7. ‚öñÔ∏è –°—Ç–∞–Ω–¥–∞—Ä—Ç–∞–¥ –æ—Ä—É—É–ª–∞—Ö\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 8. üß™ SMOTE –∞—à–∏–≥–ª–∞–∂ balance —Ö–∏–π—Ö\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
    "\n",
    "# 9. ‚úÇÔ∏è Train-test split —Ö–∏–π—Ö\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42\n",
    ")\n",
    "\n",
    "# 10. üîÅ Logistic Regression —Å—É—Ä–≥–∞–ª—Ç\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 11. üìà “Æ—Ä –¥“Ø–Ω\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"‚úÖ Accuracy: {acc:.2%}\")\n",
    "print(f\"üìä F1-score: {f1:.2%}\")\n",
    "\n",
    "# 12. üíæ –§–∞–π–ª—É—É–¥—ã–≥ —Ö–∞–¥–≥–∞–ª–∞—Ö\n",
    "joblib.dump(model, \"startup_model_logreg_smote.pkl\")\n",
    "joblib.dump(scaler, \"scaler_logreg_smote.pkl\")\n",
    "joblib.dump(label_encoders, \"label_encoders_logreg_smote.pkl\")\n",
    "joblib.dump(X.columns.tolist(), \"feature_order_logreg_smote.pkl\")\n",
    "print(\"‚úÖ –ë“Ø—Ö .pkl —Ñ–∞–π–ª—É—É–¥ SMOTE –∑–∞–≥–≤–∞—Ä–∞–∞—Ä “Ø“Ø—Å–≥—ç–≥–¥–ª—ç—ç.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e29c86c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Accuracy: 68.65%\n",
      "üìä F1-score: 72.90%\n",
      "‚úÖ –ë“Ø—Ö .pkl —Ñ–∞–π–ª—É—É–¥ Logistic Regression —Ö—É–≤–∏–ª–±–∞—Ä–∞–∞—Ä “Ø“Ø—Å–≥—ç–≥–¥–ª—ç—ç.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import joblib\n",
    "\n",
    "# 1. CSV –¥–∞—Ç–∞–≥ —É–Ω—à–∏—Ö\n",
    "df = pd.read_csv(\"C:/Users/Dell/Downloads/Ecn325 data (1).csv\")  # ‚Üê –∑–∞–º–∞–∞ —Ç–∞–∞—Ä—É—É–ª–Ω–∞ —É—É\n",
    "\n",
    "# 2. Target —Ö”©—Ä–≤“Ø“Ø–ª—ç—Ö ('acquired'=1, 'closed'=0)\n",
    "df = df[df['status'].isin(['acquired', 'closed'])].copy()\n",
    "df['status'] = df['status'].map({'acquired': 1, 'closed': 0})\n",
    "\n",
    "# 3. –•—ç—Ä—ç–≥–≥“Ø–π –±–∞–≥–∞–Ω—É—É–¥—ã–≥ —Ö–∞—Å–∞—Ö\n",
    "columns_to_drop = [\n",
    "    'Unnamed: 0', 'Unnamed: 6', 'id', 'name',\n",
    "    'object_id', 'state_code.1'\n",
    "]\n",
    "df.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# 4. –ö–∞—Ç–µ–≥–æ—Ä–∏ —Ç–∞–ª–±–∞—Ä—É—É–¥—ã–≥ Label Encode\n",
    "label_encoders = {}\n",
    "categorical_cols = df.select_dtypes(include='object').columns\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].fillna(\"unknown\")\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# 5. –¢–æ–æ–Ω –±–∞–≥–∞–Ω—É—É–¥—ã–Ω —Ö–æ–æ—Å–æ–Ω —É—Ç–≥—ã–≥ –¥—É–Ω–¥–∂–∞–∞—Ä –Ω”©—Ö”©—Ö\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].mean())\n",
    "\n",
    "# 6. Features –±–æ–ª–æ–Ω Target-–≥ —Å–∞–ª–≥–∞—Ö\n",
    "X = df.drop(columns=[\"status\"])\n",
    "y = df[\"status\"]\n",
    "\n",
    "# 7. –°—Ç–∞–Ω–¥–∞—Ä—Ç–∞–¥ –æ—Ä—É—É–ª–∞—Ö\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 8. Train-Test split —Ö–∏–π—Ö\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# 9. Logistic Regression model —Å—É—Ä–≥–∞–ª—Ç\n",
    "model = LogisticRegression(\n",
    "    class_weight='balanced',  # Imbalance-–≥ –∑–∞—Å–Ω–∞\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 10. “Æ—Ä –¥“Ø–Ω\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"üéØ Accuracy: {acc:.2%}\")\n",
    "print(f\"üìä F1-score: {f1:.2%}\")\n",
    "\n",
    "# 11. .pkl —Ñ–∞–π–ª—É—É–¥—ã–≥ —Ö–∞–¥–≥–∞–ª–∞—Ö\n",
    "joblib.dump(model, \"startup_model_logreg.pkl\")\n",
    "joblib.dump(scaler, \"scaler_logreg.pkl\")\n",
    "joblib.dump(label_encoders, \"label_encoders_logreg.pkl\")\n",
    "joblib.dump(X.columns.tolist(), \"feature_order_logreg.pkl\")\n",
    "print(\"‚úÖ –ë“Ø—Ö .pkl —Ñ–∞–π–ª—É—É–¥ Logistic Regression —Ö—É–≤–∏–ª–±–∞—Ä–∞–∞—Ä “Ø“Ø—Å–≥—ç–≥–¥–ª—ç—ç.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31b9f848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "Thanks for being a Gradio user! If you have questions or feedback, please join our Discord server and chat with us: https://discord.gg/feTf9x3ZSB\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# 1. üì¶ Logistic –∑–∞–≥–≤–∞—Ä—ã–Ω .pkl —Ñ–∞–π–ª—É—É–¥—ã–≥ –∞—á–∞–∞–ª–∞—Ö\n",
    "model = joblib.load(\"startup_model_logreg.pkl\")\n",
    "scaler = joblib.load(\"scaler_logreg.pkl\")\n",
    "label_encoders = joblib.load(\"label_encoders_logreg.pkl\")\n",
    "feature_order = joblib.load(\"feature_order_logreg.pkl\")\n",
    "\n",
    "# 2. üß† –¢–∞–∞–º–∞–≥ –≥–∞—Ä–≥–∞—Ö —Ñ—É–Ω–∫—Ü\n",
    "def predict(state, category, funding, relationships, milestones, participants, vc, angel, top500):\n",
    "    features = {col: 0 for col in feature_order}\n",
    "\n",
    "    # –ú—É–∂\n",
    "    if state in label_encoders['state_code'].classes_:\n",
    "        features['state_code'] = label_encoders['state_code'].transform([state])[0]\n",
    "    features[f\"is_{state}\" if f\"is_{state}\" in feature_order else \"is_otherstate\"] = 1\n",
    "\n",
    "    # –°–∞–ª–±–∞—Ä\n",
    "    if category in label_encoders['category_code'].classes_:\n",
    "        features['category_code'] = label_encoders['category_code'].transform([category])[0]\n",
    "    features[f\"is_{category}\" if f\"is_{category}\" in feature_order else \"is_othercategory\"] = 1\n",
    "\n",
    "    # –¢–æ–æ–Ω –±–æ–ª–æ–Ω –ª–æ–≥–∏–∫ —Ç–∞–ª–±–∞—Ä—É—É–¥\n",
    "    features['funding_total_usd'] = funding * 1_000_000\n",
    "    features['relationships'] = relationships\n",
    "    features['milestones'] = milestones\n",
    "    features['avg_participants'] = participants\n",
    "    features['has_VC'] = int(vc)\n",
    "    features['has_angel'] = int(angel)\n",
    "    features['is_top500'] = int(top500)\n",
    "\n",
    "    # Default-required\n",
    "    features['closed_at'] = 0\n",
    "    features['status'] = 0\n",
    "\n",
    "    df = pd.DataFrame([features])[feature_order]\n",
    "    df_scaled = scaler.transform(df)\n",
    "    prob = model.predict_proba(df_scaled)[0]\n",
    "    pred = model.predict(df_scaled)[0]\n",
    "\n",
    "    # ‚úÖ –ó”©–≤–ª”©–º–∂—Ç—ç–π —Ö–∞—Ä–∏—É –±—É—Ü–∞–∞—Ö\n",
    "    if pred == 1:\n",
    "        msg = f\"‚úÖ –¢–∞–Ω–∞–π —Å—Ç–∞—Ä—Ç–∞–ø –∞–º–∂–∏–ª—Ç—Ç–∞–π –±–æ–ª–æ—Ö –º–∞–≥–∞–¥–ª–∞–ª: {prob[1]:.2%}.\\n\\nüöÄ –ó”©–≤–ª”©–º–∂: –ò–ª“Ø“Ø milestone —Ö—ç—Ä—ç–≥–∂“Ø“Ø–ª–∂, —Ö”©—Ä”©–Ω–≥”© –æ—Ä—É—É–ª–∞–ª—Ç–∞–∞ —Ç–æ–≥—Ç–≤–æ—Ä—Ç–æ–π –Ω—ç–º—ç–≥–¥“Ø“Ø–ª—ç—ç—Ä—ç–π.\"\n",
    "    else:\n",
    "        msg = f\"‚ùå –¢–∞–Ω–∞–π —Å—Ç–∞—Ä—Ç–∞–ø –∞–º–∂–∏–ª—Ç–≥“Ø–π –±–æ–ª–æ—Ö –º–∞–≥–∞–¥–ª–∞–ª: {prob[0]:.2%}.\\n\\nüìâ –ó”©–≤–ª”©–º–∂: VC —ç—Å–≤—ç–ª angel —Ö”©—Ä”©–Ω–≥”© –æ—Ä—É—É–ª–∞–≥—á —Ç–∞—Ç–∞—Ö, –±–∞–≥–∏–π–Ω –±“Ø—Ç—Ü–∏–π–≥ –±—ç—Ö–∂“Ø“Ø–ª—ç—Ö —à–∞–∞—Ä–¥–ª–∞–≥–∞—Ç–∞–π –±–∞–π–∂ –º–∞–≥–∞–¥–≥“Ø–π.\"\n",
    "\n",
    "    return msg\n",
    "\n",
    "# 3. üåê Gradio chatbot-style interface\n",
    "with gr.Blocks(title=\"Startup Chatbot (LogReg)\") as chatbot:\n",
    "    gr.Markdown(\"## ü§ñ –°—Ç–∞—Ä—Ç–∞–ø –ê–º–∂–∏–ª—Ç—ã–Ω –¢–∞–∞–º–∞–≥–ª–∞–≥—á\")\n",
    "    gr.Markdown(\"–¢–∞ –∞—Å—É—É–ª—Ç–∞–¥ —Ö–∞—Ä–∏—É–ª–∞–∞–¥ ML –∑–∞–≥–≤–∞—Ä—ã–Ω —Ç–∞–∞–º–∞–≥ + –∑”©–≤–ª”©–º–∂”©”© –∞–≤–∞–∞—Ä–∞–π.\")\n",
    "\n",
    "    with gr.Row():\n",
    "        state = gr.Dropdown([\"CA\", \"NY\", \"TX\", \"MA\", \"otherstate\"], label=\"1. –ê–ª—å –º—É–∂–∏–¥ –±–∞–π—Ä–ª–∞–¥–∞–≥ –≤—ç?\")\n",
    "        category = gr.Dropdown([\"biotech\", \"software\", \"web\", \"othercategory\"], label=\"2. –Ø–º–∞—Ä —Å–∞–ª–±–∞—Ä—Ç –∞–∂–∏–ª–ª–∞–¥–∞–≥ –≤—ç?\")\n",
    "\n",
    "    funding = gr.Slider(0, 100, step=1, label=\"3. –•”©—Ä”©–Ω–≥”© (—Å–∞—è USD)\", value=1)\n",
    "    relationships = gr.Slider(0, 20, step=1, label=\"4. Co-founder –±–æ–ª–æ–Ω —Ö–∞—Ä–∏–ª—Ü–∞–∞–Ω—ã —Ç–æ–æ\", value=3)\n",
    "    milestones = gr.Slider(0, 10, step=1, label=\"5. Milestone-–∏–π–Ω —Ç–æ–æ\", value=2)\n",
    "    participants = gr.Slider(0, 10, step=1, label=\"6. –î—É–Ω–¥–∞–∂ —Ö”©—Ä”©–Ω–≥”© –æ—Ä—É—É–ª–∞–≥—á–∏–π–Ω —Ç–æ–æ\", value=4)\n",
    "\n",
    "    vc = gr.Checkbox(label=\"7. VC —Ö”©—Ä”©–Ω–≥”© –æ—Ä—É—É–ª–∞–≥—á—Ç–∞–π —é—É?\")\n",
    "    angel = gr.Checkbox(label=\"8. Angel —Ö”©—Ä”©–Ω–≥”© –æ—Ä—É—É–ª–∞–≥—á—Ç–∞–π —é—É?\")\n",
    "    top500 = gr.Checkbox(label=\"9. Top 500-–¥ –±–∞–≥—Ç—Å–∞–Ω —É—É?\")\n",
    "\n",
    "    btn = gr.Button(\"üìä –¢–∞–∞–º–∞–≥ –≥–∞—Ä–≥–∞—Ö\")\n",
    "    result = gr.Textbox(label=\"üß† –¢–∞–∞–º–∞–≥ –±–∞ –ó”©–≤–ª”©–º–∂\")\n",
    "\n",
    "    btn.click(fn=predict, inputs=[\n",
    "        state, category, funding, relationships,\n",
    "        milestones, participants, vc, angel, top500\n",
    "    ], outputs=result)\n",
    "\n",
    "chatbot.launch(share=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b6f06df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –ó–∞–≥–≤–∞—Ä—ã–Ω Accuracy: 78.38%\n",
      "üìä F1-score: 84.13%\n",
      "‚úÖ –ë“Ø—Ö .pkl —Ñ–∞–π–ª—É—É–¥ –∞–º–∂–∏–ª—Ç—Ç–∞–π —Ö–∞–¥–≥–∞–ª–∞–≥–¥–ª–∞–∞.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import joblib\n",
    "\n",
    "# 1. üì• CSV —É–Ω—à–∏—Ö\n",
    "df = pd.read_csv(\"C:/Users/Dell/Downloads/Ecn325 data (1).csv\")\n",
    "\n",
    "# 2. üéØ Target: 'status' -> acquired: 1, closed: 0\n",
    "df = df[df['status'].isin(['acquired', 'closed'])].copy()\n",
    "df['status'] = df['status'].map({'acquired': 1, 'closed': 0})\n",
    "\n",
    "# 3. üóëÔ∏è –•—ç—Ä—ç–≥–≥“Ø–π –±–∞–≥–∞–Ω—É—É–¥—ã–≥ —Ö–∞—Å–∞—Ö\n",
    "columns_to_drop = [\n",
    "    'Unnamed: 0', 'Unnamed: 6', 'id', 'name',\n",
    "    'object_id', 'state_code.1', 'labels', 'closed_at'\n",
    "]\n",
    "df.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# 4. üè∑Ô∏è –ö–∞—Ç–µ–≥–æ—Ä–∏ –±–∞–≥–∞–Ω—É—É–¥—ã–≥ Label Encode —Ö–∏–π—Ö\n",
    "label_encoders = {}\n",
    "categorical_cols = df.select_dtypes(include='object').columns\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].fillna(\"unknown\")\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# 5. üìä –¢–æ–æ–Ω –±–∞–≥–∞–Ω—É—É–¥—ã–Ω null-—É—É–¥—ã–≥ –¥—É–Ω–¥–∂–∞–∞—Ä –Ω”©—Ö”©—Ö\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].mean())\n",
    "\n",
    "# 6. üîÄ Features –±–æ–ª–æ–Ω target-–≥ —Å–∞–ª–≥–∞—Ö\n",
    "X = df.drop(columns=[\"status\"])\n",
    "y = df[\"status\"]\n",
    "\n",
    "# 7. ‚öñÔ∏è –°—Ç–∞–Ω–¥–∞—Ä—Ç–∞–¥ –æ—Ä—É—É–ª–∞—Ö\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 8. ‚úÇÔ∏è Train-Test split (stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 9. üå≤ –ó–∞–≥–≤–∞—Ä —Å—É—Ä–≥–∞–ª—Ç (–∏–ª“Ø“Ø —Å–∞–π–Ω —Ç–æ—Ö–∏—Ä–≥–æ–æ—Ç–æ–π RandomForest)\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=200, max_depth=10, class_weight='balanced', random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 10. üìà “Æ—Ä –¥“Ø–Ω —à–∞–ª–≥–∞—Ö\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"‚úÖ –ó–∞–≥–≤–∞—Ä—ã–Ω Accuracy: {acc:.2%}\")\n",
    "print(f\"üìä F1-score: {f1:.2%}\")\n",
    "\n",
    "# 11. üíæ –ë“Ø—Ö .pkl —Ñ–∞–π–ª—É—É–¥—ã–≥ —Ö–∞–¥–≥–∞–ª–∞—Ö\n",
    "joblib.dump(model, \"startup_model.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "joblib.dump(label_encoders, \"label_encoders.pkl\")\n",
    "joblib.dump(X.columns.tolist(), \"feature_order.pkl\")\n",
    "print(\"‚úÖ –ë“Ø—Ö .pkl —Ñ–∞–π–ª—É—É–¥ –∞–º–∂–∏–ª—Ç—Ç–∞–π —Ö–∞–¥–≥–∞–ª–∞–≥–¥–ª–∞–∞.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cb16637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7871\n",
      "Running on public URL: https://5abeeaa70477407867.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://5abeeaa70477407867.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import re\n",
    "import traceback\n",
    "\n",
    "# 1. –ó–∞–≥–≤–∞—Ä –±–æ–ª–æ–Ω —Ç—É—Å–ª–∞—Ö —Ñ–∞–π–ª—É—É–¥—ã–≥ –∞—á–∞–∞–ª–∞—Ö\n",
    "model = joblib.load(\"startup_model.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "label_encoders = joblib.load(\"label_encoders.pkl\")\n",
    "feature_order = joblib.load(\"feature_order.pkl\")\n",
    "\n",
    "# 2. Feature –≥–∞—Ä–≥–∞—Ö ”©—Ä–≥”©—Ç–≥”©—Å”©–Ω —Ñ—É–Ω–∫—Ü\n",
    "def extract_features(text):\n",
    "    features = {col: 0 for col in feature_order}\n",
    "\n",
    "    # --- –ë–∞–π—Ä—à–∏–ª ---\n",
    "    if re.search(r'\\b(CA|California)\\b', text, re.I):\n",
    "        if 'state_code' in label_encoders and 'CA' in label_encoders['state_code'].classes_:\n",
    "            features['state_code'] = label_encoders['state_code'].transform(['CA'])[0]\n",
    "            features['is_CA'] = 1\n",
    "    elif re.search(r'\\b(NY|New York)\\b', text, re.I):\n",
    "        if 'state_code' in label_encoders and 'NY' in label_encoders['state_code'].classes_:\n",
    "            features['state_code'] = label_encoders['state_code'].transform(['NY'])[0]\n",
    "            features['is_NY'] = 1\n",
    "    else:\n",
    "        features['is_otherstate'] = 1\n",
    "\n",
    "    # --- –°–∞–ª–±–∞—Ä ---\n",
    "    if 'category_code' in label_encoders:\n",
    "        if re.search(r'biotech', text, re.I):\n",
    "            features['category_code'] = label_encoders['category_code'].transform(['biotech'])[0]\n",
    "            features['is_biotech'] = 1\n",
    "        elif re.search(r'software', text, re.I):\n",
    "            features['category_code'] = label_encoders['category_code'].transform(['software'])[0]\n",
    "            features['is_software'] = 1\n",
    "        elif re.search(r'web', text, re.I):\n",
    "            features['category_code'] = label_encoders['category_code'].transform(['web'])[0]\n",
    "            features['is_web'] = 1\n",
    "        else:\n",
    "            features['is_othercategory'] = 1\n",
    "\n",
    "    # --- –•”©—Ä”©–Ω–≥”© –æ—Ä—É—É–ª–∞–ª—Ç ---\n",
    "    match = re.search(r'(\\d+(?:\\.\\d+)?)\\s*(—Å–∞—è|million|m)', text, re.I)\n",
    "    if match:\n",
    "        features['funding_total_usd'] = float(match.group(1)) * 1_000_000\n",
    "    else:\n",
    "        features['funding_total_usd'] = 1_000_000  # default\n",
    "\n",
    "    # --- –•”©—Ä”©–Ω–≥”© –æ—Ä—É—É–ª–∞–≥—á–∏–¥ ---\n",
    "    if \"angel\" in text.lower():\n",
    "        features['has_angel'] = 1\n",
    "    if \"vc\" in text.lower() or \"venture\" in text.lower():\n",
    "        features['has_VC'] = 1\n",
    "\n",
    "    # --- –•–∞—Ä–∏–ª—Ü–∞–∞, milestone, –æ—Ä–æ–ª—Ü–æ–≥—á–∏–¥, top500 ---\n",
    "    match = re.search(r'(\\d+)\\s+(—Ö–∞–º—Ç—Ä–∞–≥—á|co[- ]?founder|partner)', text, re.I)\n",
    "    if match:\n",
    "        features['relationships'] = int(match.group(1))\n",
    "    else:\n",
    "        features['relationships'] = 3\n",
    "\n",
    "    match = re.search(r'(\\d+)\\s+(milestone|—à–∞—Ç)', text, re.I)\n",
    "    if match:\n",
    "        features['milestones'] = int(match.group(1))\n",
    "    else:\n",
    "        features['milestones'] = 2\n",
    "\n",
    "    match = re.search(r'(\\d+)\\s+(investor|—Ö”©—Ä”©–Ω–≥”© –æ—Ä—É—É–ª–∞–≥—á)', text, re.I)\n",
    "    if match:\n",
    "        features['avg_participants'] = int(match.group(1))\n",
    "    else:\n",
    "        features['avg_participants'] = 4\n",
    "\n",
    "    if re.search(r'top\\s*500', text, re.I):\n",
    "        features['is_top500'] = 1\n",
    "\n",
    "    # –ó–∞–π–ª—à–≥“Ø–π —Ç–∞–ª–±–∞—Ä—É—É–¥\n",
    "    features['closed_at'] = 0\n",
    "    features['status'] = 0\n",
    "\n",
    "    return features\n",
    "\n",
    "# 3. –¢–∞–∞–º–∞–≥ –≥–∞—Ä–≥–∞—Ö “Ø–Ω–¥—Å—ç–Ω —Ñ—É–Ω–∫—Ü\n",
    "def smart_predict(text):\n",
    "    try:\n",
    "        input_data = extract_features(text)\n",
    "        df = pd.DataFrame([input_data])\n",
    "        df = df[feature_order]  # –∑”©–≤ –¥–∞—Ä–∞–∞–ª–ª—ã–≥ –±–∞—Ä–∏–º—Ç–∞–ª–Ω–∞\n",
    "        df_scaled = scaler.transform(df)\n",
    "\n",
    "        prob = model.predict_proba(df_scaled)[0]\n",
    "        pred = model.predict(df_scaled)[0]\n",
    "\n",
    "        if pred == 1:\n",
    "            return f\"‚úÖ –ê–º–∂–∏–ª—Ç—Ç–∞–π –±–æ–ª–æ—Ö –º–∞–≥–∞–¥–ª–∞–ª: {prob[1]:.2%}\"\n",
    "        else:\n",
    "            return f\"‚ùå –ê–º–∂–∏–ª—Ç–≥“Ø–π –±–æ–ª–æ—Ö –º–∞–≥–∞–¥–ª–∞–ª: {prob[0]:.2%}\"\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        return \"‚ö†Ô∏è –ê–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞. –¢–∞ —Ç–µ—Ä–º–∏–Ω–∞–ª–∞–∞—Å —à–∞–ª–≥–∞–Ω–∞ —É—É.\"\n",
    "\n",
    "# 4. Gradio –∏–Ω—Ç–µ—Ä—Ñ—ç–π—Å\n",
    "iface = gr.Interface(\n",
    "    fn=smart_predict,\n",
    "    inputs=gr.Textbox(lines=4, label=\"–°—Ç–∞—Ä—Ç–∞–ø—ã–Ω—Ö–∞–∞ –º—ç–¥—ç—ç–ª–ª–∏–π–≥ –±–∏—á–Ω—ç “Ø“Ø\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"–°—Ç–∞—Ä—Ç–∞–ø –ê–º–∂–∏–ª—Ç—ã–Ω –¢–∞–∞–º–∞–≥–ª–∞–≥—á\",\n",
    "    description=\"–ñ–∏—à—ç—ç: '–ú–∞–Ω–∞–π —Å—Ç–∞—Ä—Ç–∞–ø CA-–¥ –±–∞–π—Ä–ª–∞–¥–∞–≥, biotech —Å–∞–ª–±–∞—Ä—Ç –∞–∂–∏–ª–ª–∞–¥–∞–≥, 5 —Å–∞—è –¥–æ–ª–ª–∞—Ä—ã–Ω —Ö”©—Ä”©–Ω–≥”© –∞–≤—Å–∞–Ω'\",\n",
    "    examples=[\n",
    "        [\"–ú–∞–Ω–∞–π —Å—Ç–∞—Ä—Ç–∞–ø CA-–¥ –±–∞–π—Ä–ª–∞–¥–∞–≥, biotech —Å–∞–ª–±–∞—Ä—Ç –∞–∂–∏–ª–ª–∞–¥–∞–≥, 5 —Å–∞—è –¥–æ–ª–ª–∞—Ä—ã–Ω —Ö”©—Ä”©–Ω–≥”© –∞–≤—Å–∞–Ω, VC –æ—Ä–æ–ª—Ü—Å–æ–Ω\"],\n",
    "        [\"Software —Ö–∏–π–¥—ç–≥, angel —Ö”©—Ä”©–Ω–≥”© –æ—Ä—É—É–ª–∞–≥—á—Ç–∞–π\"],\n",
    "        [\"2 milestone-—Ç–æ–π, 5 —Ö”©—Ä”©–Ω–≥”© –æ—Ä—É—É–ª–∞–≥—á—Ç–∞–π, top 500-–¥ –±–∞–≥—Ç—Å–∞–Ω\"],\n",
    "        [\"New York-based startup with 3 co-founders and 2 rounds of funding\"]\n",
    "    ]\n",
    ")\n",
    "\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
